
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Q1</title><meta name="generator" content="MATLAB 9.9"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2021-11-12"><meta name="DC.source" content="Q1.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#2">a)</a></li><li><a href="#35">b)</a></li><li><a href="#39">c)</a></li><li><a href="#41">d)</a></li></ul></div><pre class="codeinput">clear; close <span class="string">all</span>; clc;
</pre><h2 id="2">a)</h2><pre class="codeinput">num_samples = 10000;
samp_size = 10;
samples = randn(num_samples, samp_size); <span class="comment">% Generating 10000 samples, each of size 10</span>
samples_mean = mean(samples, 2); <span class="comment">% Computing mean of each sample</span>
fig1 = figure();
histogram(samples_mean, 50) <span class="comment">% Plotting a histogram of the resulting estimates</span>
xlim([-2.3, 2.3])
xlabel(<span class="string">'Sample average'</span>)
ylabel(<span class="string">'Frequency'</span>)
title(<span class="string">'Histogram of sample averages'</span>)
</pre><img vspace="5" hspace="5" src="Q1_01.png" alt=""> <p>Each sample is drawn from a normal distribution with mean 0 and variance 1. The average of the samples is obtained by summing the samples and then normalizing them by the number of samples that are drawn. Therefore, the average of the samples is sum of Gaussian distributions with mean 0 and variance 1. Sum of Gaussian random variables is a Gaussian random variable. Therefore, the expected shape of the histogram of sample averages is a Normal distribution. Indeed the histogram exhibits a Normal distribution as can be seen in the figure.</p><p>Let X be the normal distribution with mean 0 and variance = 1. Therefore, we have:</p><p><img src="Q1_eq04757652772046167820.png" alt="$$X \sim N(0, 1) $$"></p><p>where, the mean and variance are:</p><p><img src="Q1_eq03960975947134244669.png" alt="$$\mu = 0 $$, $$\sigma ^2 = 1 $$"></p><p>Let the samples drawn from this distribution be:</p><p><img src="Q1_eq12626281772858632582.png" alt="$$x_1, x_2, ..., x_{N} $$"></p><p>Therefore, the average of the N samples drawn will be:</p><p><img src="Q1_eq15952636984311055452.png" alt="$$\bar{x} = \frac{\sum_i^{N} x_i}{N} $$"></p><p>The variance of the mean will hence be:</p><p><img src="Q1_eq14363992176759505077.png" alt="$$Var(\bar{x}) = Var(\frac{\sum_i^{N} x_i}{N}) $$"></p><p>Now variance of a scaled random variable is the same as the variance of the random variable scaled by square of the scaling factor. Therefore, we can re-write:</p><p><img src="Q1_eq06095717694440782093.png" alt="$$Var(\bar{x}) = \frac{1}{N^2}\times Var(\sum_i^{N} x_i) $$"></p><p>Now variance of sum of random variables is the sum of variance of each random variable and the sum of covariances of each pair of random variables, i.e.:</p><p><img src="Q1_eq15072527348082793521.png" alt="$$Var(\sum_i^{N} x_i) = \sum_i^{N} Var(x_i) + \sum_{i, j}^N Cov(x_i, x_j)&#xA;$$"></p><p>Here, each sample is drawn independent of each other. Therefore, the covariance of each pair of random variables can be assumed to be 0. Hence, we have:</p><p><img src="Q1_eq07972137634074256462.png" alt="$$Var(\sum_i^{N} x_i) = \sum_i^{N} Var(x_i) $$"></p><p>Substituting back into the equation, we get:</p><p><img src="Q1_eq01354407641840342814.png" alt="$$Var(\bar{x}) = \frac{1}{N^2}\times \sum_i^{N} Var(x_i) $$"></p><p>Each sample is drawn from X and hence, we have:</p><p><img src="Q1_eq07217619184798308019.png" alt="$$Var(x_i) = \sigma^2 $$"></p><p>Therefore,</p><p><img src="Q1_eq10835851205400288761.png" alt="$$Var(\bar{x}) = \frac{1}{N^2}\times \sum_i^{N} \sigma^2 $$"></p><p>Therefore,</p><p><img src="Q1_eq08813363110423716071.png" alt="$$Var(\bar{x}) = \frac{1}{N^2}\times N\times \sigma^2 $$"></p><p>Therefore,</p><p><img src="Q1_eq14340317732039025005.png" alt="$$Var(\bar{x}) = \frac{\sigma^2}{N} $$"></p><p>Because <img src="Q1_eq00931775698867203385.png" alt="$$\sigma ^2 = 1 $$">, the theoretical variance of the average of 10 values is:</p><p><img src="Q1_eq04728122516417841079.png" alt="$$Var(\bar{x}) = \frac{1}{10} = 0.1 $$"></p><p>The empirical variance of the 10000 estimates is:</p><pre class="codeinput">var_estimate = var(samples_mean)
</pre><pre class="codeoutput">
var_estimate =

    0.0998

</pre><p>As can be seen, indeed the empirical variance of the 10000 estimates is close to the theoretically predicted variance of the average of 10 values.</p><h2 id="35">b)</h2><pre class="codeinput">samples_median = median(samples, 2); <span class="comment">% Computing median of each sample</span>
fig2 = figure();
histogram(samples_median, 50) <span class="comment">% Plotting a histogram of the resulting estimates</span>
xlim([-2.3, 2.3])
xlabel(<span class="string">'Sample median'</span>)
ylabel(<span class="string">'Frequency'</span>)
title(<span class="string">'Histogram of sample median'</span>)
</pre><img vspace="5" hspace="5" src="Q1_02.png" alt=""> <p>The histogram of sample medians also exhibits a normal distribution</p><pre class="codeinput">fig3 = figure();
subplot(1, 2, 1)
normplot(samples_mean)
title(<span class="string">'Q-Q plot  of sample mean'</span>)
subplot(1, 2, 2)
normplot(samples_median)
title(<span class="string">'Q-Q plot of sample median'</span>)
</pre><img vspace="5" hspace="5" src="Q1_03.png" alt=""> <p>From the Q-Q plots, we see that for both sample mean and sample median, the Q-Q plots has points lie very close to the straight line with almost no deviation. Hence, we can say that both the distribution of sample mean and the distribution of sample median follow Normal distributions.</p><h2 id="39">c)</h2><pre class="codeinput">samples_minimum = min(samples, [], 2); <span class="comment">% Computing minimum of each sample</span>
samples_maximum = max(samples, [], 2); <span class="comment">% Computing maximum of each sample</span>
samples_midpoint = (samples_minimum + samples_maximum)/2; <span class="comment">% Computing midpoint of each sample</span>
fig4 = figure();
histogram(samples_midpoint, 50) <span class="comment">% Plotting a histogram of the resulting estimates</span>
xlim([-2.3, 2.3])
xlabel(<span class="string">'Sample midpoint'</span>)
ylabel(<span class="string">'Frequency'</span>)
title(<span class="string">'Histogram of sample midpoints'</span>)

fig5 = figure();
normplot(samples_midpoint)
title(<span class="string">'Q-Q plot  of sample midpoint'</span>)
</pre><img vspace="5" hspace="5" src="Q1_04.png" alt=""> <img vspace="5" hspace="5" src="Q1_05.png" alt=""> <p>From the histogram, we can see that the distribution of sample midpoints also appears to be normal. Additionally, from the Q-Q plot we can see that the points lie very close to the straight line with almost no deviation. And hence we confirm that the distribution of midpoints of samples drawn from a normal distribution is also normal.</p><h2 id="41">d)</h2><pre class="codeinput">num_samples = 10000;
samp_size = 256;
samples = randn(num_samples, samp_size); <span class="comment">% Generating 10000 samples, each of size 10</span>

sub_matrix_sizes = [8, 16, 32, 64, 128, 256];
var_mean = zeros(length(sub_matrix_sizes), 1);
var_median = zeros(length(sub_matrix_sizes), 1);
var_midpoint = zeros(length(sub_matrix_sizes), 1);
theor_var_mean = 1./sub_matrix_sizes;
<span class="keyword">for</span> i = 1:length(sub_matrix_sizes)
    sub_matrix_size = sub_matrix_sizes(i);
    sub_matrix_indices = randsample(1: samp_size, sub_matrix_size);
    sub_matrix = samples(:, sub_matrix_indices);

    <span class="comment">% Computing the unbiased estimators as above:</span>
    sub_matrix_mean = mean(sub_matrix, 2);
    sub_matrix_median = median(sub_matrix, 2);
    sub_matrix_minimum = min(sub_matrix, [], 2);
    sub_matrix_maximum = max(sub_matrix, [], 2);
    sub_matrix_midpoint = (sub_matrix_maximum - sub_matrix_minimum)/2;
    var_mean(i) = var(sub_matrix_mean);
    var_median(i) = var(sub_matrix_median);
    var_midpoint(i) = var(sub_matrix_midpoint);
<span class="keyword">end</span>

fig6 = figure();
plot(log(sub_matrix_sizes), log(var_mean), <span class="string">'r'</span>, <span class="string">'DisplayName'</span>, <span class="string">'Variance of mean'</span>);
hold <span class="string">on</span>;
plot(log(sub_matrix_sizes), log(var_median), <span class="string">'k'</span>, <span class="string">'DisplayName'</span>, <span class="string">'Variance of median'</span>);
plot(log(sub_matrix_sizes), log(var_midpoint), <span class="string">'b'</span>, <span class="string">'DisplayName'</span>, <span class="string">'Variance of midpoint'</span>);
plot(log(sub_matrix_sizes), log(theor_var_mean), <span class="string">'g'</span>, <span class="string">'DisplayName'</span>, <span class="string">'Theoretical variance of mean'</span>);
xlabel(<span class="string">'log(sample size)'</span>)
ylabel(<span class="string">'log(variance)'</span>)
title(<span class="string">'log-log plot of variance and sample size'</span>)
legend(<span class="string">'Location'</span>, <span class="string">'southwest'</span>);
</pre><img vspace="5" hspace="5" src="Q1_06.png" alt=""> <p class="footer"><br><a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2020b</a><br></p></div><!--
##### SOURCE BEGIN #####
clear; close all; clc;

%% a)
num_samples = 10000;
samp_size = 10;
samples = randn(num_samples, samp_size); % Generating 10000 samples, each of size 10
samples_mean = mean(samples, 2); % Computing mean of each sample
fig1 = figure();
histogram(samples_mean, 50) % Plotting a histogram of the resulting estimates
xlim([-2.3, 2.3])
xlabel('Sample average')
ylabel('Frequency')
title('Histogram of sample averages')

%%
% Each sample is drawn from a normal distribution with mean 0 and variance
% 1. The average of the samples is obtained by summing the samples and then
% normalizing them by the number of samples that are drawn. Therefore, the
% average of the samples is sum of Gaussian distributions with mean 0 and
% variance 1. Sum of Gaussian random variables is a Gaussian random
% variable. Therefore, the expected shape of the histogram of sample
% averages is a Normal distribution. Indeed the histogram exhibits a Normal
% distribution as can be seen in the figure.

%%
% Let X be the normal distribution with mean 0 and variance = 1. Therefore,
% we have:
%%
% $$X \sim N(0, 1) $$
%%
% where, the mean and variance are:
%%
% $$\mu = 0 $$, $$\sigma ^2 = 1 $$
%%
% Let the samples drawn from this distribution be:
%%
% $$x_1, x_2, ..., x_{N} $$
%%
% Therefore, the average of the N samples drawn will be:
%%
% $$\bar{x} = \frac{\sum_i^{N} x_i}{N} $$
%%
% The variance of the mean will hence be:
%%
% $$Var(\bar{x}) = Var(\frac{\sum_i^{N} x_i}{N}) $$
%%
% Now variance of a scaled random variable is the same as the
% variance of the random variable scaled by square of the scaling factor.
% Therefore, we can re-write:
%%
% $$Var(\bar{x}) = \frac{1}{N^2}\times Var(\sum_i^{N} x_i) $$
%%
% Now variance of sum of random variables is the sum of variance of each
% random variable and the sum of covariances of each pair of random
% variables, i.e.:
%%
% $$Var(\sum_i^{N} x_i) = \sum_i^{N} Var(x_i) + \sum_{i, j}^N Cov(x_i, x_j)
% $$
%%
% Here, each sample is drawn independent of each other. Therefore, the
% covariance of each pair of random variables can be assumed to be 0.
% Hence, we have:
%%
% $$Var(\sum_i^{N} x_i) = \sum_i^{N} Var(x_i) $$
%%
% Substituting back into the equation, we get:
%%
% $$Var(\bar{x}) = \frac{1}{N^2}\times \sum_i^{N} Var(x_i) $$
%%
% Each sample is drawn from X and hence, we have:
%%
% $$Var(x_i) = \sigma^2 $$
%%
% Therefore,
%%
% $$Var(\bar{x}) = \frac{1}{N^2}\times \sum_i^{N} \sigma^2 $$
%%
% Therefore,
%%
% $$Var(\bar{x}) = \frac{1}{N^2}\times N\times \sigma^2 $$
%%
% Therefore,
%%
% $$Var(\bar{x}) = \frac{\sigma^2}{N} $$
%%
% Because $$\sigma ^2 = 1 $$, the theoretical variance of the average of 10
% values is:
%%
% $$Var(\bar{x}) = \frac{1}{10} = 0.1 $$
%%
% The empirical variance of the 10000 estimates is:
%%
var_estimate = var(samples_mean)
%%
% As can be seen, indeed the empirical variance of the 10000 estimates is
% close to the theoretically predicted variance of the average of 10
% values.

%% b)
samples_median = median(samples, 2); % Computing median of each sample
fig2 = figure();
histogram(samples_median, 50) % Plotting a histogram of the resulting estimates
xlim([-2.3, 2.3])
xlabel('Sample median')
ylabel('Frequency')
title('Histogram of sample median')

%%
% The histogram of sample medians also exhibits a normal distribution

%%
fig3 = figure();
subplot(1, 2, 1)
normplot(samples_mean)
title('Q-Q plot  of sample mean')
subplot(1, 2, 2)
normplot(samples_median)
title('Q-Q plot of sample median')

%%
% From the Q-Q plots, we see that for both sample mean and sample median,
% the Q-Q plots has points lie very close to the straight line with almost
% no deviation. Hence, we can say that both the distribution of sample mean
% and the distribution of sample median follow Normal distributions.

%% c)
samples_minimum = min(samples, [], 2); % Computing minimum of each sample
samples_maximum = max(samples, [], 2); % Computing maximum of each sample
samples_midpoint = (samples_minimum + samples_maximum)/2; % Computing midpoint of each sample
fig4 = figure();
histogram(samples_midpoint, 50) % Plotting a histogram of the resulting estimates
xlim([-2.3, 2.3])
xlabel('Sample midpoint')
ylabel('Frequency')
title('Histogram of sample midpoints')

fig5 = figure();
normplot(samples_midpoint)
title('Q-Q plot  of sample midpoint')

%%
% From the histogram, we can see that the distribution of sample midpoints
% also appears to be normal. Additionally, from the Q-Q plot we can see
% that the points lie very close to the straight line with almost no
% deviation. And hence we confirm that the distribution of midpoints of
% samples drawn from a normal distribution is also normal.

%% d)
num_samples = 10000;
samp_size = 256;
samples = randn(num_samples, samp_size); % Generating 10000 samples, each of size 10

sub_matrix_sizes = [8, 16, 32, 64, 128, 256];
var_mean = zeros(length(sub_matrix_sizes), 1);
var_median = zeros(length(sub_matrix_sizes), 1);
var_midpoint = zeros(length(sub_matrix_sizes), 1);
theor_var_mean = 1./sub_matrix_sizes;
for i = 1:length(sub_matrix_sizes)
    sub_matrix_size = sub_matrix_sizes(i);
    sub_matrix_indices = randsample(1: samp_size, sub_matrix_size);
    sub_matrix = samples(:, sub_matrix_indices);
    
    % Computing the unbiased estimators as above:
    sub_matrix_mean = mean(sub_matrix, 2);
    sub_matrix_median = median(sub_matrix, 2);
    sub_matrix_minimum = min(sub_matrix, [], 2);
    sub_matrix_maximum = max(sub_matrix, [], 2);
    sub_matrix_midpoint = (sub_matrix_maximum - sub_matrix_minimum)/2;
    var_mean(i) = var(sub_matrix_mean);
    var_median(i) = var(sub_matrix_median);
    var_midpoint(i) = var(sub_matrix_midpoint);
end

fig6 = figure();
plot(log(sub_matrix_sizes), log(var_mean), 'r', 'DisplayName', 'Variance of mean');
hold on;
plot(log(sub_matrix_sizes), log(var_median), 'k', 'DisplayName', 'Variance of median');
plot(log(sub_matrix_sizes), log(var_midpoint), 'b', 'DisplayName', 'Variance of midpoint');
plot(log(sub_matrix_sizes), log(theor_var_mean), 'g', 'DisplayName', 'Theoretical variance of mean');
xlabel('log(sample size)')
ylabel('log(variance)')
title('log-log plot of variance and sample size')
legend('Location', 'southwest');
##### SOURCE END #####
--></body></html>