{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a medical study, doctors aimed to examine whether aspirin can reduce the incidents of heart attacks. To this aim, they recruited a large amount of subjects and divided them to aspirin group and placebo group. After receiving the aspirin or the placebo pill for a period of time, doctors observed that people in the aspirin group ended up only having 104 heart attacks incidents, and people in the placebo group ended up having 189 incidents.\n",
    "\n",
    "Given the data, we can compute the percentages of the heart attack incident for both groups, and compute a ratio. The fact that the ratio is smaller than 1 suggests that aspirin therapy is effective in preventing heart attacks. But how sure are we of this estimate? Does the 95%\n",
    "confidence interval include 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from random import choices\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import sys\n",
    "sys.path.append('/Users/hff/Desktop/NYU/5th year/Fall semester/MathTools/Labs/Lab9')\n",
    "from scipy.io import loadmat\n",
    "dataStruct = loadmat('regress1.mat')\n",
    "\n",
    "np.random.seed(0)\n",
    "cMAP1  = np.array([[50,205,50],[255,165,0]])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------YOUR CODE STARTS HERE-------------------------\n",
    "#aspirin group\n",
    "aspirin_heart   = 104\n",
    "aspirin_total   = 11037\n",
    "aspirin_data    = ###YOUR CODE\n",
    "\n",
    "#placebo group\n",
    "placebo_heart   = 189\n",
    "placebo_total   = 11034\n",
    "placebo_data    = ###YOUR CODE\n",
    "\n",
    "#Calculate statistic for original sample\n",
    "ratio_empirical = ###YOUR CODE\n",
    "print('The ratio computed from empirical data is ', str(ratio_empirical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's say we bootstrap (sample with replacement) 10,000 times\n",
    "n_boot          = int(1e4)\n",
    "#ratio_boot is used to store the ratio for each bootstrapped dataset\n",
    "ratio_boot      = np.zeros(n_boot)\n",
    "for i in range(n_boot):\n",
    "    #resample aispiring data\n",
    "    boot_asp         = ###YOUR CODE\n",
    "    #resample placebo data \n",
    "    boot_placebo     = ###YOUR CODE\n",
    "    n_boot_asp       = np.sum(boot_asp)\n",
    "    n_boot_placebo   = np.sum(boot_placebo) \n",
    "    #Calculate statistic for resampled data      \n",
    "    ratio_boot[i]    = ###YOUR CODE\n",
    "\n",
    "#Find 95% confidence interval\n",
    "ratio_boot_sorted = ###YOUR CODE # Sort ratio_boots from lowest to highest\n",
    "lower_bound_ind   = ###YOUR CODE # Find index of 2.5% value\n",
    "upper_bound_ind   = ###YOUR CODE # Find index of 97.5% value\n",
    "\n",
    "#Use lower/higher index to find value corresponding to 2.5%/97.5% position\n",
    "lower_bound       = ###YOUR CODE\n",
    "upper_bound       = ###YOUR CODE\n",
    "#----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the bootstrapped ratios and the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(ratio_boot, bins=50, color=cMAP1[0,], alpha=0.6)\n",
    "plt.axvline(x=ratio_empirical, color='r', linestyle='-')\n",
    "plt.axvline(x=lower_bound, color='k', linestyle='--')\n",
    "plt.axvline(x=upper_bound, color='k', linestyle='-.')\n",
    "plt.xlabel('Ratio'); plt.ylabel('Counts');\n",
    "plt.legend(['Bootstrapped ratios', 'Empirical ratio', '95% CI (lower bound)',\n",
    "    '95 % CI (upper bound)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that the 95% confidence interval does not include 1 implies that we can be very confident that the aspirin therapy is effective in preventing heart attacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Cross validation (leave-one-out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is a resampling method that uses different portions of the data to test and train a model on different iterations. The goal of  cross-validation is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like overfitting and to give an insight on how the model will generalize to a new (or unknown) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's first visualize the data\n",
    "x = dataStruct['x'].T\n",
    "y = dataStruct['y'].T\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize= (6,4))\n",
    "plt.scatter(x, y, s = 100, color = cMAP1[0,], alpha = 0.5)\n",
    "plt.xlim([-2,3]); plt.ylim([-3,4]); plt.xlabel('x')\n",
    "plt.ylabel('y'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit the data with polynomial linear models without using cross validation. This will serve as a comparison to see how cross validation alters our interpretation of the 'best' model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of data points\n",
    "n_pts    = y.shape[1]\n",
    "x_zero   = np.ones([1,n_pts])\n",
    "#All regressors that we will use for each fit\n",
    "XX       = np.stack((x_zero[0], x[0], x[0]**2,x[0]**3,x[0]**4,x[0]**5,x[0]**6,\n",
    "                     x[0]**7,x[0]**8,x[0]**9,x[0]**10,x[0]**11), axis = 0)\n",
    "#Number of regressors (should be 6)\n",
    "n_models = 12\n",
    "order    = np.arange(0,n_models)\n",
    "#initialize matrices mse_vec (which stores mean squared error) and fit_mat (which stores \n",
    "#predicted y values)\n",
    "mse_vec  = []\n",
    "fit_mat  = []\n",
    "\n",
    "#------------------------YOUR CODE STARTS HERE-------------------------\n",
    "#Loop through each polynomial order\n",
    "for i in range(n_models):\n",
    "    #Get betas for polynomial order\n",
    "    betas =  ###YOUR CODE #np.polyfit(x[0],y[0],i)\n",
    "    \n",
    "    #Get fit by multiplying betas with regressors\n",
    "    print('Order = ' + str(i) + ', beta: ' + str(betas))\n",
    "    fit   =  ###YOUR CODE #np.polyval(betas,x)\n",
    "    \n",
    "    #Add fit to fit matrix\n",
    "    fit_mat.append(fit) \n",
    "    \n",
    "    #Find and save mean square error\n",
    "    mse = ###YOUR CODE\n",
    "    mse_vec.append(mse)\n",
    "#----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=3, ncols=4,figsize= (14,9))\n",
    "for i in range(n_models):\n",
    "    idx_row = i//4\n",
    "    idx_col = i%4\n",
    "    ax[idx_row, idx_col].scatter(x, y, s = 100, color = cMAP1[0,], alpha = 0.5)\n",
    "    ax[idx_row, idx_col].plot(x[0], fit_mat[i], color = cMAP1[1,], linewidth = 3)\n",
    "    ax[idx_row, idx_col].set_xlim([-2,3]); ax[idx_row, idx_col].set_ylim([-3,4]); \n",
    "    ax[idx_row, idx_col].set_xlabel('x'); ax[idx_row, idx_col].set_ylabel('y'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's re-do the model fitting with leave-one-out cross validation and then re-evaluate our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's fit this data with polynomials:\n",
    "\n",
    "#------------------------YOUR CODE STARTS HERE-----------------------------\n",
    "#Initialize a matrix to hold MSE values for each model for each cross validation\n",
    "mse_train = np.zeros([n_models, n_pts])\n",
    "mse_test  = np.zeros([n_models, n_pts])\n",
    "for i in range(n_models): \n",
    "    mse_xval_i = []\n",
    "    for j in range(n_pts):\n",
    "        #Make j the test set\n",
    "        idx_slc = ###YOUR CODE\n",
    "        x_train = ###YOUR CODE\n",
    "        x_test  = ###YOUR CODE\n",
    "        \n",
    "        y_train = ###YOUR CODE\n",
    "        y_test  = ###YOUR CODE\n",
    "        \n",
    "        #Compute the fit (Get betas using training data)\n",
    "        betas         = ###YOUR CODE\n",
    "        fit_train     = ###YOUR CODE\n",
    "        mse_train[i][j] = ###YOUR CODE\n",
    "        \n",
    "        #Test the fit (Get model's prediction for test point)\n",
    "        fit_test       = ###YOUR CODE\n",
    "        mse_test[i][j] = ###YOUR CODE #MSE of test fit\n",
    "\n",
    "#find lowest MSE\n",
    "mean_mse_test = np.mean(mse_test,1)\n",
    "min_mse       = np.min(mean_mse_test)\n",
    "min_ind       = np.argmin(mean_mse_test)\n",
    "mean_mse_train = np.mean(mse_train,1)\n",
    "#----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the mean MSE \n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize= (8,6))\n",
    "plt.scatter(min_ind, mean_mse_train[min_ind], s = 100, c = 'red')\n",
    "plt.plot(order, mean_mse_test, color = cMAP1[1],ls = '-', lw=3, ms=5)\n",
    "plt.plot(order, mean_mse_train, color = cMAP1[0],ls = '-', lw=3, ms=5)\n",
    "plt.xlim([-0.5,n_models-0.5]);  plt.xlabel('Order')\n",
    "plt.ylabel('Mean squared error (MSE)')\n",
    "plt.legend(['MSE of the ''best'' model','MSE (training set)', 'MSE (test set)'])\n",
    "plt.show()\n",
    "\n",
    "#Which model is best?\n",
    "print('The best model is when order = ' + str(order[min_ind]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Model Comparison (AIC, BIC)\n",
    "In this section, we will fit a psychometric function to simulated data, and compute AIC/BIC using the negative log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first load the fake data\n",
    "dataStruct2 = loadmat('TOJ_fakeData.mat')\n",
    "\n",
    "#t_diff represents SOA (the timing of the auditory \n",
    "#stimulus - the timing of the visual stimulus in ms). Positive values \n",
    "#represent the visual stimulus coming before the auditory stimulus; \n",
    "#negative values represent the auditory stimulus coming first. Like in a\n",
    "#real experiment, all the SOA's are randomized.\n",
    "t_diff    = dataStruct2['fakeData'][0][0][0]\n",
    "\n",
    "#bool_V1st stores binary responses\n",
    "#1: V first; 0: A first\n",
    "bool_V1st = dataStruct2['fakeData'][0][1][0]\n",
    "\n",
    "#we can also code the responses in the opposite way\n",
    "#1: A first; 0: V first\n",
    "#(this becomes handy when you compute negative log likelihood later on) \n",
    "bool_V2nd = 1 - bool_V1st\n",
    "\n",
    "#before fitting, let's visualize the fake data\n",
    "s_unique  = np.unique(t_diff) #unique SOA's\n",
    "lenS      = len(s_unique) #the number of unique SOA's \n",
    "nTTrials  = len(t_diff) #number of total trials\n",
    "numTrials = nTTrials/lenS #number of trials per level\n",
    "\n",
    "#As in a real experiment, all the SOA's are randomized. We want to\n",
    "#visualize the proportion of V-first responses as a function of SOA, so we\n",
    "#have to first organize the responses. We do so by storing responses for\n",
    "#the same SOA in one row.\n",
    "r_org       = np.zeros([lenS, int(numTrials)])\n",
    "for i in range(lenS): r_org[i,:] = bool_V1st[t_diff == s_unique[i]]\n",
    "#compute the number of V-first responses for each SOA\n",
    "nT_V1st      = np.sum(r_org,1)\n",
    "#compute the proportion of V-first responses for each SOA\n",
    "P_V1st       = nT_V1st/numTrials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting starts here\n",
    "cMAP = np.array([[200, 40, 40],[255, 128, 0], [13, 183, 200]])/255\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize= (8,6))\n",
    "plt.scatter(s_unique, P_V1st, s = 150, color = cMAP[2])\n",
    "plt.xlim([-450, 450]); plt.ylim([-0.1,1.1]); plt.xlabel('t_A - t_V (ms)')\n",
    "plt.ylabel('Probability of reporting ''V-first'''); plt.xticks(s_unique[0:2:-1])\n",
    "plt.yticks([0,0.5,1]); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's test three hypothesized models:\n",
    "\n",
    "M1: we assume that this participant does not have any bias (i.e., PSS corresponds to a difference of 0 in time). Additionally, we assume that this participant is always attentive to the stimuli (i.e., lapse rate = 0). The only unknown free parameter we need to measure is sigma (the slope of the psychometric curve).\n",
    "\n",
    "M2: we assume that this participant has a bias (i.e., the physical temporal difference has to be nonzero for him/her to perceive simultaneity. As in M1, this participant is assumed to pay attention to the task all the time. Therefore, this model has two free parameters, the center and the slope of the psychometric curve. \n",
    "\n",
    "M3: we assume that this participant occassionally made mistakes during the experiment (i.e., nonzero lapse rate). This model has three free parameters, the center and the slope of the psychometric curve as well as the lapse rate.\n",
    "\n",
    "Note that these three models are NESTED!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------YOUR CODE STARTS HERE-----------------------------\n",
    "#Let's test three models:\n",
    "numM     = 3 #number of models\n",
    "numP     = [1,2,3] #number of free parameters for M1, M2, M3 respectively\n",
    "M1       = lambda x,p: norm.cdf(x, 0, p) \n",
    "M2       = lambda x,p: norm.cdf(x, p[0], p[1])\n",
    "M3       = lambda x,p: ###YOUR CODE\n",
    "fmat     = [M1, M2, M3] \n",
    "\n",
    "#define upper and lower bounds\n",
    "lb       = [[80], [-50, 80], [ -50, 80, 1e-1]]\n",
    "ub       = [[200], [150, 200], [150, 200, 0.2]]\n",
    "bds      = [(80,200), ((-50,150),(80,200)), ((-50,150),(80,200),(1e-1,0.2))]\n",
    "init_fun = lambda a,b: np.random.rand(len(a))*(np.array(b)-np.array(a)) + a\n",
    "\n",
    "min_NLL, L_test,AIC, BIC = np.zeros(numM), np.zeros(numM), np.zeros(numM), np.zeros(numM)\n",
    "estP     = []\n",
    "\n",
    "#loop through the three models\n",
    "for m in range(numM):\n",
    "    #the initial point for matlab to start searching\n",
    "    init = tuple(init_fun(lb[m], ub[m]))\n",
    "    #negative log likelihood\n",
    "    nLogL = lambda p: ###YOUR CODE\n",
    "    \n",
    "    #use minimize to fit\n",
    "    if m == 0:\n",
    "        fits = minimize(nLogL, ((init),), method = 'L-BFGS-B', bounds = (bds[m],))\n",
    "    else: fits = minimize(nLogL, init, method = 'L-BFGS-B', bounds = (bds[m]))\n",
    "    \n",
    "    min_NLL[m] = fits.fun\n",
    "    estP.append(fits.x)\n",
    "    #compute the AIC/BIC\n",
    "    AIC[m] = ###YOUR CODE\n",
    "    BIC[m] = ###YOUR CODE\n",
    "#--------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the data along with the model fits\n",
    "lstyle = ['--','-.',':']\n",
    "cMAP = np.array([[200, 40, 40],[255, 128, 0], [13, 183, 200]])/255\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize= (8,6))\n",
    "plt.scatter(s_unique, P_V1st, s = 150, color = cMAP[2])\n",
    "for m in range(numM):\n",
    "    predP = fmat[m](s_unique, estP[m])\n",
    "    plt.plot(s_unique, predP, color = cMAP[m], linewidth = 2, linestyle = lstyle[m])\n",
    "plt.xlim([-450, 450]); plt.ylim([-0.1,1.1]); plt.xlabel('t_A - t_V (ms)')\n",
    "plt.ylabel('Probability of reporting ''V-first'''); plt.xticks(s_unique[0:2:-1])\n",
    "plt.yticks([0,0.5,1]); plt.legend(['Model fits (M1)', 'Model fits (M2)',\n",
    "                                   'Model fits (M3)', 'Fake data'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot AIC BIC\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1,figsize= (8,6))\n",
    "\n",
    "sns.heatmap([AIC - np.min(AIC)], linewidth=0.5, ax = axes[0],cmap=\"YlGnBu\",annot=True,linewidths=.5)\n",
    "sns.heatmap([BIC - np.min(BIC)], linewidth=0.5, ax = axes[1],cmap=\"YlGnBu\",annot=True,linewidths=.5)\n",
    "axes[0].set_ylabel('AIC - min(AIC)');axes[1].set_ylabel('BIC - min(BIC)')\n",
    "axes[0].set_xticklabels(['M1','M2','M3']); axes[1].set_xticklabels(['M1','M2','M3'])\n",
    "axes[0].set_yticks([]); axes[1].set_yticks([]); plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - AIC/BIC vs. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave-one-out cross validation starts here\n",
    "min_NLL_LOOCV, L_test_LOOCV = np.zeros([numM, nTTrials]), np.zeros([numM, nTTrials])\n",
    "\n",
    "#------------------------YOUR CODE STARTS HERE-----------------------------\n",
    "#loop through all the trials\n",
    "for i in range(nTTrials):\n",
    "    #display the counter see where we are at (ends at 169)\n",
    "    #print(i)   \n",
    "    \n",
    "    #select the trial indices\n",
    "    idx_slc       = ###YOUR CODE\n",
    "    #selected SOA's\n",
    "    t_diff_slc    = ###YOUR CODE\n",
    "    t_diff_test   = ###YOUR CODE\n",
    "\n",
    "    #selected response\n",
    "    bool_V1st_slc = ###YOUR CODE\n",
    "    bool_V2nd_slc = ###YOUR CODE\n",
    "    \n",
    "    #loop through all the three models\n",
    "    for m in range(numM):\n",
    "        #the initial point for matlab to start searching\n",
    "        init   = init_fun(lb[m], ub[m])\n",
    "        #negative log likelihood\n",
    "        nLogL  = lambda p: ###YOUR CODE\n",
    "        \n",
    "        #use minimize to fit\n",
    "        if m == 0:\n",
    "            fits = minimize(nLogL, ((init),), method = 'L-BFGS-B', bounds = (bds[m],))\n",
    "        else: fits = minimize(nLogL, init, method = 'L-BFGS-B', bounds = (bds[m]))\n",
    "        \n",
    "        min_NLL_LOOCV[m,i] = fits.fun\n",
    "        estP.append(fits.x)\n",
    "        \n",
    "        #compute the likelihood of \n",
    "        L_test_LOOCV[m,i] = ###YOUR CODE\n",
    "#-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This part of the code shows you the results of cross-validation. \n",
    "#No changes are required.\n",
    "\n",
    "#define a function that find 95% confidence intervals\n",
    "get95CI      = lambda v,n: [v[int(np.ceil(0.025*n))], v[int(np.floor(0.975*n))]]\n",
    "#compare the likelihood of M3 with that of M2\n",
    "Lratio_M3_M2 = L_test_LOOCV[2]/L_test_LOOCV[1]\n",
    "#compare the likelihood of M3 with that of M1\n",
    "Lratio_M3_M1 = L_test_LOOCV[2]/L_test_LOOCV[0]\n",
    "#compare the likelihood of M2 with that of M1\n",
    "Lratio_M2_M1 = L_test_LOOCV[1]/L_test_LOOCV[0]\n",
    "#put them together\n",
    "Lratio       = [Lratio_M3_M2,Lratio_M3_M1,Lratio_M2_M1]\n",
    "\n",
    "#print out the proportion of each likelihood ratio greater than 1\n",
    "print('p(Likelihood ratio btw M3 & M2 > 1) = ' + str(np.sum(Lratio_M3_M2>1)/nTTrials))\n",
    "print('p(Likelihood ratio btw M3 & M1 > 1) = ' + str(np.sum(Lratio_M3_M1>1)/nTTrials))\n",
    "print('p(Likelihood ratio btw M2 & M1 > 1) = ' + str(np.sum(Lratio_M2_M1>1)/nTTrials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lratio_CI, Lratio_mean = [],[]\n",
    "for i in range(numM):\n",
    "    Lratio[i].sort()\n",
    "    #call get95CI.m for computing confidence intervals\n",
    "    Lratio_CI.append(get95CI(Lratio[i], nTTrials))\n",
    "    #compute the mean likelihood ratio\n",
    "    Lratio_mean.append(np.mean(Lratio[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot histograms for likelihood ratios\n",
    "edg = np.arange(0.85,1.5,0.02)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1,figsize= (9,6))\n",
    "for i in range(numM):\n",
    "    axes[i].hist(Lratio[i], bins = 20, color= cMAP[2], alpha=0.3)\n",
    "    axes[i].axvline(x = 1, color='k', linestyle='--')\n",
    "    axes[i].set_xlim([0.85, 1.5]); axes[i].set_ylim([0, 50])\n",
    "    axes[2].set_xlabel('Likelihood ratio'); axes[i].set_ylabel('Counts')\n",
    "axes[0].set_title('M3 vs. M2'); axes[1].set_title('M3 vs. M1'); axes[2].set_title('M2 vs. M1'); \n",
    "axes[0].set_xticks([]); axes[1].set_xticks([]);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
